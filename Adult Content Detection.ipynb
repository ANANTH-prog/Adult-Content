{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the necessary imports\n",
    "from fastai import *\n",
    "#imports all the necessary pieces from the library. fastai is designed to be usable in a read–eval–print loop(REPL)\n",
    "from fastai.vision import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#This module provides a portable way of using operating system dependent functionality\n",
    "import os\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "#to get the count of elements using counter\n",
    "from collections import Counter\n",
    "#this is for all learner.vision\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import cv2\n",
    "import os\n",
    "#Function to extract frames\n",
    "#directory path, where my video images will be stored\n",
    "mydir = r'../input/datajpg'\n",
    "try:\n",
    "    if not os.path.exists(os.path.dirname(mydir)):\n",
    "        os.makedirs(os.path.dirname(mydir))\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "#Capture vidoe from video file\n",
    "cap = cv2.VideoCapture(r\"../input/datajpg/mery.mp4.mp4\")\n",
    "#Counter Variable\n",
    "count = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "    \n",
    "if ret == True:\n",
    "    print('Read %d frame: ' % count, ret)\n",
    "# save frame as JPEG file\n",
    "cv2.imwrite(os.path.join(r'../input/datajpg', \"frame{:d}.jpg\".format(count)), frame)\n",
    "count += 1\n",
    "\n",
    "#cv2.destroyAllWindows()   \n",
    "# When everything done, release the capture\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the line which gives the path of  data set\n",
    "#retreving captured frames from local file path\n",
    "data_folder = Path(\"../input/my-nsfw-dataset\")\n",
    "#If you want to quickly get a set of random transforms that have worked well in a wide range of tasks, you should use the get_transforms function. The most important parameters to adjust are do_flip and flip_vert, depending on the type of images you have.\n",
    "#get_transforms returns a tuple of two lists of transforms: one for the training set and one for the validation set \n",
    "trfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=10.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can tell (for JPEGs) PIL only accepts it as a valid JPEG Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataBunch from_* methods are used, the size and resize_method \n",
    "data = (ImageList.from_folder(data_folder)\n",
    "        .split_by_rand_pct(0.1)\n",
    "        .label_from_folder()\n",
    "        .add_test_folder(\"../input/my-nsfw-dataset\")\n",
    "        .transform(trfms, size=128)\n",
    "        .databunch(bs=64, device= torch.device('cpu'))\n",
    "        .normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computer vision learner\n",
    "#vision.learner is the module that defines the cnn_learner method, to easily get a model suitable for transfer learning.\n",
    "#os.getcwd This method returns current working directory of a process\n",
    "learn = cnn_learner(data, models.resnet101, metrics=[error_rate, accuracy], model_dir = os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore lr from start_lr to end_lr over num_it iterations in learn. If stop_div, stops when loss diverges.\n",
    "learn.lr_find(stop_div=False, num_it=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the loss vs learning rage\n",
    "learn.recorder.plot(suggestion = True)\n",
    "# the point which gives minimum loss at particular learning point\n",
    "min_grad_lr = learn.recorder.min_grad_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-03\n",
    "# no of ephocs to produce accuracy,loss and error rate \n",
    "learn.fit_one_cycle(50, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path = Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls - list the contents of the current directory\n",
    "ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
